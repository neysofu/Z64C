\chapter{Evaluation \& Search}

\section{Monte Carlo Tree Search}
Training will use the modular architecture of the engine and train the various
neural networks with the outputs of the others.

I need to train:
* Hot2board
* Board2moves
* Increment2board

What's the relation between the estimated score [0-1] and the move strenght
[0-1]? Given one, one can find the other. So the move strenght is not relative
to other moves, but only to the estimated score.

I need an optimal algorithm.
Basically, it start playing moves given board positions. I add an exploration
component by playing also random or unlikely moves. At every move, I get an
estimated score and a move.

So my net is at the same time an actor and a critic: gives me an action (or more
than one), and an estimated winning score. How do I train this? I want to
bootstrap the winning score. I will train based on the advantage instead, so
that it's smarter about it.

Ok, maybe I got it. Using a normal optimizer like Adam, I backtrace part of the
net to maximize the estimated score, and I train the estimated score based on
the temporal difference learning formula. Now I should be set, I have the
training figured out, and I can devote my time to implement (and train!) Z64C
v0.2.

Notes on perft:
I want to develop a perft so that I don't need to worry about checks. It would
be much, much faster! What's the quirk?
A move is illegal if, at the next move, there is a pseudolegal move to capture the
king.

I need a struct Board where I can extremely rapidly say which moves are in the
tensor and if they are legal.

Cavalli: 8
Pedoni: 28
Torri: 14
Alfieri: 13
Re: 8

Architettura REDIS:
Sorted set con Id dei search node e priorita'.

Non capisco se dovrei fare l'update delle statistiche... mi serve davvero?
Spero davvero di no, perche' altrimenti sarei nei guai. Diventa un magnitudo di
complessita' temporale piu' lento. Mi serve che la ricerca sia velocissima. La
ricerca deve fare:

* Legality check (pseudo?)
  Come faccio a gestire una pseudo legality checking? Il problema non e' affatto
  lo scacco matto, ma lo stallo, che invece e' difficile da prevedere.


Z64C starts search from the top of its search table by creating a visitor. The
visitor architecture is extremely easy to parallelize: one can just add more
visitors and update the search table in more places at the same time. The
visitor works by hammering down the search tree, finding a good minimum while
mantaining exploration. The behaviour of visitors is customizable directly from
C using function pointers. This allows for different playing styles or - more
simply - to explore unsure nodes during training. Exploration routine:


\algbegin X (Multiplication). blah blah blah blah...

\algstep X1. [{\textit Do stuff\/}] blah blah blah

\algstep X2. Terminate the algorithm.\quad\slug

1. Initialization. Create a visitor at the top node.
2. Fall. Descend the tree by choosing a semirandom path.
3. Impact. Evaluate the node at the visitor and add only its children that are
   considered useful.
4. Pruning. Sometimes Step Impact make us understand that a whole branch of the
   tree is not viable.
4. Bouncing. Recursively move the visitor up the tree for a certain number of
   nodes, which is determined by a random value. Go back to stage 2.

Just like MCTS, this algorithm is easily parallelizable, but this one reduces
the amount of nodes that need to be visited when the search table grows bigger
and bigger, because it takes advantage of proximity of nodes.

The search table also needs other features:

* Pruning. I don't want the search table to just get bigger and bigger. It also
  must let some branches go when we realize they're not as promising as we
  thought they would be.
* Node prediction. While the GPU is computing, the CPU is choosing the next
  nodes to feed to the GPU and saving them in a buffer, ready to be streamed in
  a batch.
* Data locality and memory pools. Nodes close in the tree shuld also be close in
  memory, for better data locality and better chance for cache hits.
* Transpositions. Transpositions are stored by Robin Hood hashing with
  a counter of how many times they were met during search. During pruning I know
  when transpositions are actually finished and I can kill them.
  to delete all transpositions
  and then
* Number of children to add at new nodes. Only new children that have a certain
  probability to improve the current score are kept, those that fall under that
  are directly removed.

The problem with TTable is that it's on the RAM, so it's slow. I want Z64C to be
using CPU 100% and this only happens when I have better data locality.
long-term all tactics and lines explored, which can't possibly fit into a
smaller data structure. I also need to figure out a cache-friendly version of
TTable though, such that I can fetch subsets of TTable very quickly.


/section{Neural network architecture}
\section{\ac{MCST}}
