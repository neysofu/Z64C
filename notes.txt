Search algo: CUSTOM WITH NEURAL NETWORK but it's similar to MCTS

Possible AlphaZero missing feature: AlphaZero does not understand when to look
deeper! This is a huge deal and I can take advantage of it. Also, AlphaZero
doesn't know how to incrementally evaluate, thus making search much slower. The
program also does not search during the opponent's turn! BTW: thinking during
the opponent's turn is useful to save time in the next turn, thus one must also
consider the opponent's strength. Evaluation must also be tunable, i.e. it can
evaluate only a subset of the chessboard if necessary, to increase speed.

IT NEEDS TO BE ABLE TO LEARN EVERYTHING IT NEEDS TO KNOW TO PLAY FLAWLESSLY.

Invalid moves are approximated within reasonable limits.

ARCHITECTURE
============

Resignation happens when the probability of winning drops below [0.05].

1. Evaluation function.

   I just need to find an embedding of chess positions, then for the most part
   the problem is solved. Also, I need a mapping bewteen the vector space and my
   internal representation of chess positions.

   Time control:
     There are so many time controls that I wouldn't know which ones to choose,
	 so I represent every time control with a pressure indicator for white [1]
	 and for black [1], which generally indicates how much more thinking they
	 can do before they lose the game.

   Problem statement:
     I have an extremely big graph (infinite for all practical purposes)
	 representing all the possible chess positions
	 as nodes; each edge is labelled (a certain kind of move) and directed.
	 By exploring the graph during a training session, Z64C must be able to find
	 a relatively low-dimensional embedding of each node (and possible even
	 edges). The only information available to Z64C is the current chess
	 position vector, it must automatically figure out edges and which ones look
	 promising. The output of the neural network is a feature vector with [192]
	 dimensions and a predicted score [1].

   Learning process:
     First, accumulate many, many vectors of chessboards and store them in a
	 database. Millions, if not billions. At that point, from each of those,
	 train the network to generalize the embedding to unseen positions by
	 walking over the graph (i.e. self-play).

   Finally, it is possible to train another network that, given a one-not
   encoding of the chess position, transforms it into a vector representation.
   This is necessary if we want to just load and analyze positions (which is a
   desiderable feature). However, this only happens after the main evaluation
   network is trained and without any changes to the original network.

   Input:
	* Chessboard embedding
	* Time pressure [0-1]
	* Halfmove clock [0-1] (n. moves divided by 50)
	* Audacity score [0-1] (how much to go for a win instead of a draw)

2. MCTS-like search function.

   Input:
      A sequence of moves, each with an associated score [0-1].
   Mechanism:
      For every move suggested by the output of the evaluation function with a
	  certain probability [0-1], the search function randomly evaluates the
	  resulting positions from those moves if a random variable is greater than
	  its probability. The output of a search is also stored to disk according
	  to that probability, so that it may be more easily retrieved at later
	  stages.
   Output:
      A single move.

Main procedure output:
----------------------
Move: the move to perform
Bool: A draw is desiderable (right now. The chess librabry checks the rules and,
if a drawn can be offered or claimed, it does it.)

TRAINING STRATEGY
=================
Training will use a combination of several learning methods, some supervised and
others not. I have at my disposal:

* Chess 960 (5%)
* Endgame tables
* Mixed opening book and not during training, so that it can learn to use it
  when useful and not to when it's not.
